{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 83735,
          "databundleVersionId": 9881586,
          "sourceType": "competition"
        },
        {
          "sourceId": 10000887,
          "sourceType": "datasetVersion",
          "datasetId": 6155781
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "🕵️‍♂️🤖 ✅ MediaAnalyzer: AI Truth Detector📊🛡️⭐",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "vIN33LxtAWXR"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "gemini_long_context_path = kagglehub.competition_download('gemini-long-context')\n",
        "kane0068_deception_data_path = kagglehub.dataset_download('kane0068/deception-data')\n",
        "google_gemini_1_5_flash_api_api_gemini_1_5_flash_1_path = kagglehub.model_download('google/gemini-1.5-flash-api/Api/gemini-1.5-flash/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Lwk8UxHyAWXU"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🕵️‍♂️ MediaAnalyzer: Truth in the Age of Misinformation\n",
        "\n",
        "## 🤖 Powered by Google Gemini 1.5\n",
        "## 📊 Multi-Modal Media Verification\n",
        "## 🛡️ Deception Detection Platform"
      ],
      "metadata": {
        "id": "hdzQdpVXAWXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MediaAnalyzer: The Truth Detection Revolution**\n",
        "- In today's digital age, we're drowning in information. But how much of it can we truly trust?\n",
        "- Misinformation is everywhere. Fake videos, doctored texts, misleading audio clips - they're not just annoying, they're dangerous. Individuals, businesses, and entire societies are at risk.\n",
        "- Meet MediaAnalyzer - the world's most advanced AI-powered media verification platform. We don't just detect deception; we dissect it.\n"
      ],
      "metadata": {
        "id": "Jg3NYMj0AWXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Video Analysis**\n",
        "\n",
        "**Our advanced video analysis goes beyond surface level. We track**\n",
        "\n",
        "- Exact transcriptions with speaker identification\n",
        "- Behavioral micro-signals\n",
        "- Physiological response tracking\n",
        "- Deception probability assessment\n",
        "\n",
        "## **2. Text Verification**\n",
        "\n",
        "**Textual content isn't safe from scrutiny. MediaAnalyzer:**\n",
        "\n",
        "- Identifies factual inaccuracies\n",
        "- Highlights grammatical errors\n",
        "- Reveals logical inconsistencies\n",
        "- Provides precise corrections\n",
        "\n",
        "## **3. Audio Forensics**\n",
        "\n",
        "**Even audio isn't beyond our reach. We provide:**\n",
        "\n",
        "- Complete transcriptions\n",
        "- Statement verifications\n",
        "- Contextual insights\n",
        "- Speaker bias detection"
      ],
      "metadata": {
        "id": "pZYNtGDJAWXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## - While traditional AI models struggle with 32,000 tokens, Gemini 1.5 processes up to 2 MILLION tokens. That's equivalent to:\n",
        "\n",
        "    - 100,000 lines of code\n",
        "    - 10 years of text messages\n",
        "    - 16 complete novels\n",
        "\n",
        "  \n",
        "- Powered by Google's Gemini AI, our platform uses multiple sophisticated analysis layers. We don't just scan - we understand.\n",
        "\n",
        "-   Complete transparency with detailed token usage reports. Know exactly how your AI analysis works, down to the last token.\n",
        "\n",
        "# **In a world of deepfakes, misinformation, and digital manipulation, MediaAnalyzer is your guardian of truth.**"
      ],
      "metadata": {
        "id": "LZ93Tn7RAWXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "from typing import List, Dict, Any, Tuple ,Optional\n",
        "import google.generativeai as genai\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "class MediaAnalyzer:\n",
        "    def __init__(self, api_key: str):\n",
        "        #Initialize the analyzer wih API credentials.\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.generation_config = {\n",
        "            \"temperature\": 0.1,\n",
        "            \"top_p\": 1.0,\n",
        "            \"top_k\": 32,\n",
        "            \"max_output_tokens\": 4096,\n",
        "        }\n",
        "        self.model = genai.GenerativeModel(\n",
        "            model_name=\"gemini-1.5-flash\",\n",
        "            generation_config=self.generation_config,\n",
        "        )\n",
        "\n",
        "\n",
        "        self.uploaded_files = {}  # Track uploaded files and their states\n",
        "        self.total_prompts = 0  # Track total number of prompts\n",
        "        self.token_stats = {\n",
        "            \"summary\": {\n",
        "                \"total_prompts\": 0,\n",
        "                \"total_input_tokens\": 0,\n",
        "                \"total_output_tokens\": 0,\n",
        "                \"total_tokens\": 0\n",
        "            },\n",
        "            \"details\": []\n",
        "        }\n",
        "\n",
        "    def _track_token_usage(self, response):\n",
        "        #Track token usage for each model response.\n",
        "\n",
        "        try:\n",
        "            # Check if the response has usage metadata\n",
        "            if hasattr(response, 'usage_metadata'):\n",
        "                input_tokens = getattr(response.usage_metadata, 'prompt_token_count', 0)\n",
        "                output_tokens = getattr(response.usage_metadata, 'candidates_token_count', 0)\n",
        "                total_tokens = getattr(response.usage_metadata, 'total_token_count', 0)\n",
        "\n",
        "                # Update summary stats\n",
        "                self.token_stats['summary']['total_prompts'] += 1\n",
        "                self.token_stats['summary']['total_input_tokens'] += input_tokens\n",
        "                self.token_stats['summary']['total_output_tokens'] += output_tokens\n",
        "                self.token_stats['summary']['total_tokens'] += total_tokens\n",
        "\n",
        "                # Store detailed stats for this response\n",
        "                self.token_stats['details'].append({\n",
        "                    'input_tokens': input_tokens,\n",
        "                    'output_tokens': output_tokens,\n",
        "                    'total_tokens': total_tokens\n",
        "                })\n",
        "\n",
        "                # Calculate average tokens per prompt\n",
        "                if self.token_stats['summary']['total_prompts'] > 0:\n",
        "                    self.token_stats['summary']['average_tokens_per_prompt'] = (\n",
        "                        self.token_stats['summary']['total_tokens'] /\n",
        "                        self.token_stats['summary']['total_prompts']\n",
        "                    )\n",
        "\n",
        "                # Print token usage for this response\n",
        "                print(f\"Token Usage - Input: {input_tokens}, Output: {output_tokens}, Total: {total_tokens}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error tracking token usage: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "    def _validate_file(self, file_path: str, expected_mime_type: str) -> bool:\n",
        "        \"\"\"\n",
        "        Validate file exists and matches expected type.\n",
        "        Returns True if valid, False otherwise.\n",
        "        \"\"\"\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Error: File not found - {file_path}\")\n",
        "            return False\n",
        "\n",
        "        # Basic MIME type validation based on file extension\n",
        "        extension = os.path.splitext(file_path)[1].lower()\n",
        "        mime_map = {\n",
        "            '.mp4': 'video/mp4',\n",
        "            '.txt': 'text/plain',\n",
        "            '.mp3': 'audio/mpeg'\n",
        "        }\n",
        "\n",
        "        if extension not in mime_map or mime_map[extension] != expected_mime_type:\n",
        "            print(f\"Error: Invalid file type. Expected {expected_mime_type}\")\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _upload_file_with_retry(self, file_path: str, mime_type: str, max_retries: int = 3) -> Optional[genai.types.File]:\n",
        "        \"\"\"\n",
        "        Upload file with retry logic and validation.\n",
        "        Returns File object if successful, None if failed.\n",
        "        \"\"\"\n",
        "        if not self._validate_file(file_path, mime_type):\n",
        "            return None\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                print(f\"Upload attempt {attempt + 1}/{max_retries}\")\n",
        "                file = genai.upload_file(file_path, mime_type=mime_type)\n",
        "\n",
        "                # Wait briefly to ensure file is active\n",
        "                time.sleep(2)\n",
        "\n",
        "                # Store file reference\n",
        "                self.uploaded_files[file_path] = file\n",
        "                return file\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Upload attempt {attempt + 1} failed: {str(e)}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(2 ** attempt)  # Exponential backoff\n",
        "                else:\n",
        "                    print(\"Max retries reached. Upload failed.\")\n",
        "                    return None\n",
        "\n",
        "    def analyze_media(self, file_path: str, media_type: str) -> Dict[str, Any]:\n",
        "\n",
        "        #Unified media analysis method with proper error handling.\n",
        "\n",
        "        mime_types = {\n",
        "            \"video\": \"video/mp4\",\n",
        "            \"text\": \"text/plain\",\n",
        "            \"audio\": \"audio/mpeg\"\n",
        "        }\n",
        "\n",
        "        if media_type not in mime_types:\n",
        "            return {\"error\": f\"Unsupported media type: {media_type}\"}\n",
        "\n",
        "        try:\n",
        "            # Upload file with retry logic\n",
        "            file_obj = self._upload_file_with_retry(file_path, mime_types[media_type])\n",
        "            if not file_obj:\n",
        "                return {\"error\": \"File upload failed\"}\n",
        "\n",
        "            # Choose appropriate analysis method\n",
        "            if media_type == \"video\":\n",
        "                return self.analyze_video(file_obj)\n",
        "            elif media_type == \"text\":\n",
        "                return self.analyze_text(file_obj)\n",
        "            elif media_type == \"audio\":\n",
        "                return self.analyze_audio(file_obj)\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"error\": f\"Analysis error: {str(e)}\",\n",
        "                \"file_path\": file_path,\n",
        "                \"media_type\": media_type\n",
        "            }\n",
        "\n",
        "    def analyze_video(self, video_file: genai.types.File) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze video for potential deception indicators.\"\"\"\n",
        "        try:\n",
        "            chat = self.model.start_chat()\n",
        "\n",
        "            # Verify file is ready and processed\n",
        "            print(\"Processing video...\")\n",
        "            processing_start = time.time()\n",
        "            file = genai.get_file(video_file.name)\n",
        "            while file.state.name == \"PROCESSING\":\n",
        "                elapsed = time.time() - processing_start\n",
        "                print(f\"\\rProcessing... {elapsed:.1f}s\", end=\"\", flush=True)\n",
        "                time.sleep(2)\n",
        "                file = genai.get_file(file.name)\n",
        "            print(\"\\nVideo processing complete!\")\n",
        "\n",
        "            # Sequence of analysis prompts\n",
        "            analysis_prompts = [\n",
        "                (\"Transcription\", \"\"\"\n",
        "                Analyze this video and provide:\n",
        "                1. Exact transcription of all spoken words with timestamps\n",
        "                2. Speaker identification (name or description)\n",
        "                3. Basic scene description\n",
        "\n",
        "                Format as:\n",
        "                TIMESTAMP: [SPEAKER]: [SPOKEN TEXT]\n",
        "                \"\"\"),\n",
        "                (\"Behavioral Analysis\", \"\"\"\n",
        "                Based on the video, analyze these specific behavioral indicators:\n",
        "\n",
        "                1. Eye Movement Patterns:\n",
        "                - Direction of gaze\n",
        "                - Blink rate\n",
        "                - Eye contact duration\n",
        "                - Pupil dilation\n",
        "\n",
        "                2. Facial Expressions:\n",
        "                - Micro-expressions\n",
        "                - Emotion displays\n",
        "                - Asymmetrical expressions\n",
        "                - Timing of expressions\n",
        "\n",
        "                3. Body Language:\n",
        "                - Hand gestures\n",
        "                - Body positioning\n",
        "                - Tension indicators\n",
        "                - Movement patterns\n",
        "\n",
        "                Provide timestamps and detailed descriptions for each observation.\n",
        "                \"\"\"),\n",
        "                (\"Statement Analysis\", \"\"\"\n",
        "                Analyze the truthfulness of statements in the video:\n",
        "\n",
        "                For each major statement:\n",
        "                1. Note the exact statement and timestamp\n",
        "                2. Analyze for:\n",
        "                   - Internal consistency\n",
        "                   - Logical coherence\n",
        "                   - Verifiable facts\n",
        "                   - Contradictions\n",
        "                3. If false, provide the correct information\n",
        "                4. Rate confidence in analysis (0-100%)\n",
        "\n",
        "                Focus especially on:\n",
        "                - Qualifying language\n",
        "                - Changes in detail level\n",
        "                - Emotional congruence\n",
        "                - Response latency\n",
        "                \"\"\"),\n",
        "                (\"Physiological Analysis\", \"\"\"\n",
        "                Analyze physiological indicators of potential deception:\n",
        "\n",
        "                1. Voice Analysis:\n",
        "                - Pitch changes\n",
        "                - Speech rate variations\n",
        "                - Voice tremors\n",
        "                - Volume changes\n",
        "\n",
        "                2. Physical Responses:\n",
        "                - Breathing patterns\n",
        "                - Swallowing frequency\n",
        "                - Facial color changes\n",
        "                - Muscle tension\n",
        "\n",
        "                Provide specific timestamps and descriptions.\n",
        "                \"\"\"),\n",
        "                (\"Final Assessment\", \"\"\"\n",
        "                Based on all previous analyses, provide:\n",
        "                1. Overall deception probability (0-100%)\n",
        "                2. List of definitely true statements\n",
        "                3. List of potentially deceptive statements\n",
        "                4. Confidence rating in the analysis\n",
        "                5. Any limitations or caveats\n",
        "                \"\"\")\n",
        "            ]\n",
        "\n",
        "            combined_analysis = {}\n",
        "\n",
        "            # Process each analysis prompt\n",
        "            for prompt_name, prompt in analysis_prompts:\n",
        "                print(f\"Processing {prompt_name}...\")\n",
        "\n",
        "                # For the first prompt, include the video file\n",
        "                if prompt_name == \"Transcription\":\n",
        "                    response = chat.send_message([prompt, video_file])\n",
        "                else:\n",
        "                    response = chat.send_message(prompt)\n",
        "\n",
        "                # Track token usage\n",
        "                self._track_token_usage(response)\n",
        "\n",
        "                # Store analysis result\n",
        "                combined_analysis[prompt_name.upper()] = self._parse_response(response.text)\n",
        "                print(f\"{prompt_name} analysis complete.\")\n",
        "\n",
        "            return combined_analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Analysis error: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            return {\"error\": error_msg}\n",
        "\n",
        "\n",
        "    def analyze_text(self, text_file: genai.types.File) -> Dict[str, Any]:\n",
        "        ##Analyze text file for incorect statements and provide corrections\n",
        "        try:\n",
        "            chat = self.model.start_chat()\n",
        "\n",
        "            # Analysis prompts with increasing depth\n",
        "            analysis_prompts = [\n",
        "                (\"Content Analysis\", \"\"\"\n",
        "                Please analyze this text document and:\n",
        "                1. Identify any factually incorrect statements\n",
        "                2. Point out grammatical errors\n",
        "                3. Highlight logical inconsistencies\n",
        "                4. Provide corrections for each issue found\n",
        "\n",
        "                Format your response as:\n",
        "                ISSUE TYPE: [Original Text] -> [Correction]\n",
        "                EXPLANATION: [Why this needs correction]\n",
        "                \"\"\"),\n",
        "                (\"Verification\", \"\"\"\n",
        "                For each correction suggested, please:\n",
        "                1. Rate confidence in the correction (0-100%)\n",
        "                2. Provide source or reasoning for the correction\n",
        "                3. Note if any alternative interpretations are possible\n",
        "                \"\"\"),\n",
        "                (\"Contextual Insights\", \"\"\"\n",
        "                Provide additional context about:\n",
        "                1. The writing style\n",
        "                2. Potential author biases\n",
        "                3. Cultural or historical context that might influence the text\n",
        "                4. Any subtle nuances or implied meanings\n",
        "                \"\"\")\n",
        "            ]\n",
        "\n",
        "            # Store analysis results\n",
        "            combined_analysis = {}\n",
        "\n",
        "            # Process each analysis prompt\n",
        "            for prompt_name, prompt in analysis_prompts:\n",
        "                print(f\"Processing {prompt_name}...\")\n",
        "\n",
        "                # For the first prompt, include the text file\n",
        "                if prompt_name == \"Content Analysis\":\n",
        "                    response = chat.send_message([prompt, text_file])\n",
        "                else:\n",
        "                    response = chat.send_message(prompt)\n",
        "\n",
        "                # Track token usage\n",
        "                self._track_token_usage(response)\n",
        "\n",
        "                # Store analysis result\n",
        "                combined_analysis[prompt_name.replace(\" \", \"_\").upper()] = self._parse_response(response.text)\n",
        "                print(f\"{prompt_name} analysis complete.\")\n",
        "\n",
        "            return combined_analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def _parse_response(self, response_text: str) -> List[str]:\n",
        "        \"\"\"Parse response text into structured format.\"\"\"\n",
        "        if not response_text:\n",
        "            return [\"No data available\"]\n",
        "\n",
        "        # Split response into lines and clean\n",
        "        lines = [line.strip() for line in response_text.split('\\n') if line.strip()]\n",
        "\n",
        "        # If no meaningful content, return default\n",
        "        if not lines:\n",
        "            return [\"No meaningful data detected\"]\n",
        "\n",
        "        return lines\n",
        "\n",
        "\n",
        "\n",
        "    def analyze_audio(self, audio_file: genai.types.File) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze audio file for incorrect statements and provide corrections.\"\"\"\n",
        "        try:\n",
        "            chat = self.model.start_chat()\n",
        "\n",
        "            # Analysis prompts with increasing depth\n",
        "            analysis_prompts = [\n",
        "                (\"Transcription\", \"\"\"\n",
        "                Please analyze this audio file and provide:\n",
        "                1. Complete transcription with timestamps\n",
        "                2. Identify any incorrect statements or claims\n",
        "                3. Note any unclear or ambiguous passages\n",
        "\n",
        "                Format as:\n",
        "                TIMESTAMP: [SPEAKER]: [SPOKEN TEXT]\n",
        "                ISSUES: [List any problems found]\n",
        "                \"\"\"),\n",
        "                (\"Error Analysis\", \"\"\"\n",
        "                For each identified issue, please provide:\n",
        "                1. The incorrect statement\n",
        "                2. The correct information\n",
        "                3. Confidence level in the correction (0-100%)\n",
        "                4. Context or explanation for why it's incorrect\n",
        "                \"\"\"),\n",
        "                (\"Quality Assurance\", \"\"\"\n",
        "                Please verify:\n",
        "                1. Are there any cultural or contextual factors that might affect interpretation?\n",
        "                2. Could any statements be correct in different contexts?\n",
        "                3. Are there any ambiguous statements that need clarification?\n",
        "                4. Provide insights into speaker's tone, emphasis, and potential biases\n",
        "                \"\"\")\n",
        "            ]\n",
        "\n",
        "            # Store analysis results\n",
        "            combined_analysis = {}\n",
        "\n",
        "            # Process each analysis prompt\n",
        "            for prompt_name, prompt in analysis_prompts:\n",
        "                print(f\"Processing {prompt_name}...\")\n",
        "\n",
        "                # For the first prompt, include the audio file\n",
        "                if prompt_name == \"Transcription\":\n",
        "                    response = chat.send_message([prompt, audio_file])\n",
        "                else:\n",
        "                    response = chat.send_message(prompt)\n",
        "\n",
        "                # Track token usage\n",
        "                self._track_token_usage(response)\n",
        "\n",
        "                # Store analysis result\n",
        "                combined_analysis[prompt_name.replace(\" \", \"_\").upper()] = self._parse_response(response.text)\n",
        "                print(f\"{prompt_name} analysis complete.\")\n",
        "\n",
        "            return combined_analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "    def generate_report(self) -> str:\n",
        "        \"\"\"Generate a detailed token usage report.\"\"\"\n",
        "        report = \"\"\"\n",
        "TOKEN USAGE REPORT\n",
        "=================\n",
        "Total Prompts: {total_prompts}\n",
        "Total Input Tokens: {total_input_tokens:,}\n",
        "Total Output Tokens: {total_output_tokens:,}\n",
        "Total Tokens: {total_tokens:,}\n",
        "Average Tokens per Prompt: {avg_tokens:.2f}\n",
        "\n",
        "Detailed Token Breakdown:\n",
        "\"\"\".format(\n",
        "            total_prompts=self.token_stats['summary']['total_prompts'],\n",
        "            total_input_tokens=self.token_stats['summary']['total_input_tokens'],\n",
        "            total_output_tokens=self.token_stats['summary']['total_output_tokens'],\n",
        "            total_tokens=self.token_stats['summary']['total_tokens'],\n",
        "            avg_tokens=self.token_stats['summary'].get('average_tokens_per_prompt', 0)\n",
        "        )\n",
        "\n",
        "        # Add details of each prompt's token usage\n",
        "        for i, detail in enumerate(self.token_stats['details'], 1):\n",
        "            report += f\"\"\"\n",
        "Prompt {i}:\n",
        "  Input Tokens: {detail['input_tokens']:,}\n",
        "  Output Tokens: {detail['output_tokens']:,}\n",
        "  Total Tokens: {detail['total_tokens']:,}\n",
        "\"\"\"\n",
        "\n",
        "        return report\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Initializing system...\")\n",
        "        user_secrets = UserSecretsClient()\n",
        "        api_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
        "\n",
        "        analyzer = MediaAnalyzer(api_key)\n",
        "        print(\"Initialization complete!\")\n",
        "\n",
        "        # Define media files to process\n",
        "        media_files = {\n",
        "            \"video\": \"/kaggle/input/deception-data/video.mp4\",\n",
        "            \"text\": \"/kaggle/input/deception-data/fake_text.txt\",\n",
        "            \"audio\": \"/kaggle/input/deception-data/academic_misconceptions.mp3\"\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        # Process each media file\n",
        "        for media_type, file_path in media_files.items():\n",
        "            if os.path.exists(file_path):\n",
        "                print(f\"\\nProcessing {media_type}...\")\n",
        "                start_time = time.time()\n",
        "\n",
        "                # Analyze media\n",
        "                analysis = analyzer.analyze_media(file_path, media_type)\n",
        "\n",
        "                # Generate and save report\n",
        "                if \"error\" not in analysis:\n",
        "                    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    report_filename = f\"{media_type}_analysis_report_{timestamp}.txt\"\n",
        "\n",
        "                    with open(report_filename, \"w\", encoding='utf-8') as f:\n",
        "                        json.dump(analysis, f, indent=2)\n",
        "\n",
        "                    print(f\"Analysis completed in {time.time() - start_time:.2f} seconds\")\n",
        "                    print(f\"Report saved to: {report_filename}\")\n",
        "                else:\n",
        "                    print(f\"Analysis failed: {analysis['error']}\")\n",
        "\n",
        "                results[media_type] = analysis\n",
        "\n",
        "        # Print summary\n",
        "        print(\"\\nAnalysis Summary:\")\n",
        "        for media_type, analysis in results.items():\n",
        "            status = \"Success\" if \"error\" not in analysis else f\"Failed: {analysis['error']}\"\n",
        "            print(f\"{media_type.capitalize()}: {status}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nCritical error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "    main()\n",
        "    end_time = time.time()\n",
        "    print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-27T23:09:21.872169Z",
          "iopub.execute_input": "2024-11-27T23:09:21.872606Z",
          "iopub.status.idle": "2024-11-27T23:12:13.32119Z",
          "shell.execute_reply.started": "2024-11-27T23:09:21.872509Z",
          "shell.execute_reply": "2024-11-27T23:12:13.320061Z"
        },
        "id": "RX1IV42iAWXY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "############################################################\n",
        "def print_report(filename):\n",
        "    file_path = os.path.join('/kaggle/working', filename)\n",
        "    console = Console()\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            content = json.load(file)\n",
        "\n",
        "\n",
        "            console.rule(f\"[bold blue]{filename.upper()}[/bold blue]\")\n",
        "\n",
        "\n",
        "            for section, details in content.items():\n",
        "                console.print(f\"\\n[bold green]{section}[/bold green]\")\n",
        "\n",
        "\n",
        "                if isinstance(details, list):\n",
        "                    table = Table(show_header=False)\n",
        "                    for item in details:\n",
        "                        table.add_row(str(item))\n",
        "                    console.print(table)\n",
        "\n",
        "\n",
        "                elif isinstance(details, dict):\n",
        "                    table = Table(title=section)\n",
        "                    table.add_column(\"Key\")\n",
        "                    table.add_column(\"Value\")\n",
        "                    for key, value in details.items():\n",
        "                        table.add_row(str(key), str(value))\n",
        "                    console.print(table)\n",
        "\n",
        "                else:\n",
        "                    console.print(str(details))\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(f\"[red]Error reading {filename}: {e}[/red]\")\n",
        "##########################################################################################\n",
        "\n",
        "output_files = [f for f in os.listdir('/kaggle/working') if f.endswith('.txt')]\n",
        "\n",
        "for filename in output_files:\n",
        "    print_report(filename)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-27T23:26:05.86108Z",
          "iopub.execute_input": "2024-11-27T23:26:05.861453Z",
          "iopub.status.idle": "2024-11-27T23:26:06.046839Z",
          "shell.execute_reply.started": "2024-11-27T23:26:05.861421Z",
          "shell.execute_reply": "2024-11-27T23:26:06.045627Z"
        },
        "id": "VUSnakIHAWXa"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}